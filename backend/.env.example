# =============================================================================
# Retrieva - Environment Configuration
# =============================================================================
# This file serves as a template. Copy to .env and configure for your environment.
#
# ENVIRONMENTS:
# - Development: Docker-based local services (MongoDB, Redis, Qdrant)
# - Staging: Managed services (MongoDB Atlas, etc.) for testing
# - Production: Production-grade managed services with full security
# =============================================================================

# Server Configuration
PORT=3007
NODE_ENV=development  # development | staging | production

# =============================================================================
# MongoDB Configuration
# =============================================================================
# DEVELOPMENT (Docker): Use local MongoDB container
MONGODB_URI=mongodb://localhost:27017/enterprise_rag

# STAGING/PRODUCTION (Atlas): Use MongoDB Atlas
# MONGODB_URI=mongodb+srv://<user>:<password>@<cluster>.mongodb.net/enterprise_rag?retryWrites=true&w=majority

# =============================================================================
# Redis Configuration
# =============================================================================
# DEVELOPMENT (Docker): Local Redis container (port 6378 to avoid conflicts)
REDIS_URL=redis://localhost:6378

# STAGING/PRODUCTION: Self-hosted Redis container (recommended) or managed Redis
# REDIS_URL=redis://:<password>@redis:6379

# =============================================================================
# Qdrant Configuration
# =============================================================================
# DEVELOPMENT (Docker): Local Qdrant container
QDRANT_URL=http://localhost:6333
QDRANT_COLLECTION_NAME=documents

# STAGING/PRODUCTION: Qdrant Cloud or managed instance
# QDRANT_URL=https://<cluster>.qdrant.io
# QDRANT_API_KEY=<your-api-key>

# =============================================================================
# Azure OpenAI Configuration (REQUIRED)
# =============================================================================
# This application uses Azure OpenAI for all LLM and embedding operations.
#
# To get these values after Terraform deployment, run:
#   terraform output -raw backend_env_config
#
# Or retrieve API key manually:
#   az cognitiveservices account keys list --name <openai-account-name> \
#     --resource-group <resource-group> --query "key1" -o tsv

# Provider Configuration
LLM_PROVIDER=azure_openai
EMBEDDING_PROVIDER=azure

# Azure OpenAI API Key (required)
AZURE_OPENAI_API_KEY=

# Azure OpenAI Endpoint URL (from Terraform output or Azure Portal)
# Example: https://oai-rag-backend-abc123.openai.azure.com
AZURE_OPENAI_ENDPOINT=

# Model Deployments (names must match Terraform deployment names)
AZURE_OPENAI_LLM_DEPLOYMENT=gpt-4o-mini
AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-3-small

# API Version (use stable version for production)
AZURE_OPENAI_API_VERSION=2024-02-15-preview

# Embedding concurrency - parallel API calls to Azure OpenAI
# Increase for faster indexing, but respect your Azure tier limits:
# - S0 (Basic): 10 concurrent
# - Standard: 20 concurrent
# Small servers (2 vCPU / 4GB): use 5 to avoid CPU/memory pressure
# Check Azure Portal > your OpenAI resource > Rate Limits for exact values
EMBEDDING_MAX_CONCURRENCY=10

# Worker Concurrency
# Controls how many documents are indexed in parallel by BullMQ workers
# Lower values reduce CPU/memory pressure on small servers
# Recommended: 2-3 for 2 vCPU, 5-10 for 4+ vCPU
INDEX_WORKER_CONCURRENCY=3
BATCH_SIZE=10

# =============================================================================
# LLM Model Settings
# =============================================================================
LLM_MODEL=gpt-4o-mini
EMBEDDING_MODEL=text-embedding-3-small
JUDGE_LLM_MODEL=gpt-4o-mini

# LLM Generation Parameters
LLM_TEMPERATURE=0.3

# =============================================================================
# LLM Timeout Protection
# =============================================================================
# Prevents hung requests when LLM service is slow or unresponsive
LLM_INVOKE_TIMEOUT=60000           # Timeout for invoke calls (60s default)
LLM_STREAM_INITIAL_TIMEOUT=30000   # Timeout for first streaming chunk (30s)
LLM_STREAM_CHUNK_TIMEOUT=10000     # Timeout between streaming chunks (10s)
LLM_MAX_TOKENS=2000

# Global Request Timeouts
# Prevents hung requests from blocking the server
REQUEST_TIMEOUT_MS=30000           # Default request timeout (30s)
STREAMING_TIMEOUT_MS=180000        # Streaming endpoint timeout (3 min)
SYNC_TIMEOUT_MS=600000             # Sync operation timeout (10 min)
EMBEDDING_TIMEOUT_MS=120000        # Embedding batch timeout (2 min)
LLM_TOP_P=1
LLM_TOP_K=50

# =============================================================================
# Notion Integration
# =============================================================================
# OAuth Configuration (for connecting Notion workspaces)
NOTION_CLIENT_ID=
NOTION_CLIENT_SECRET=
NOTION_REDIRECT_URI=http://localhost:3007/api/v1/notion/callback

# Webhook Configuration (for real-time updates from Notion)
# Generate a secure secret for webhook signature verification
# openssl rand -base64 32
NOTION_WEBHOOK_SECRET=

# Rate Limiting
NOTION_API_RATE_LIMIT=2

# RAG Cache Configuration
RAG_CACHE_ENABLED=true
RAG_CACHE_TTL=3600

# =============================================================================
# JWT Authentication (REQUIRED for production)
# =============================================================================
# CRITICAL: These secrets MUST be set in production. The server will NOT start without them.
# Generate strong secrets (minimum 32 characters) using:
#   openssl rand -base64 48
# Or:
#   node -e "console.log(require('crypto').randomBytes(48).toString('base64'))"
JWT_ACCESS_SECRET=
JWT_REFRESH_SECRET=
JWT_ACCESS_EXPIRY=15m
JWT_REFRESH_EXPIRY=7d

# =============================================================================
# Encryption Key (for Notion tokens)
# =============================================================================
# CRITICAL: Required to encrypt/decrypt Notion OAuth access tokens
# Generate a 32-byte key (64 hex characters):
#   node -e "console.log(require('crypto').randomBytes(32).toString('hex'))"
ENCRYPTION_KEY=

# Key Rotation Support:
# When rotating keys:
# 1. Generate new key using command above
# 2. Copy current ENCRYPTION_KEY to ENCRYPTION_KEY_V{n} (n = current version)
# 3. Set new key as ENCRYPTION_KEY
# 4. Increment ENCRYPTION_KEY_VERSION
# 5. Run: node scripts/rotateEncryptionKeys.js
#
# Example after first rotation:
#   ENCRYPTION_KEY=<new_key>
#   ENCRYPTION_KEY_V1=<old_key>
#   ENCRYPTION_KEY_VERSION=2
ENCRYPTION_KEY_VERSION=1
# ENCRYPTION_KEY_V1=  # Set to previous key during rotation

# =============================================================================
# Frontend URL (for OAuth redirects)
# =============================================================================
# The URL of your frontend application for OAuth callback redirects
FRONTEND_URL=http://localhost:3000

# =============================================================================
# CORS Configuration (REQUIRED for production)
# =============================================================================
# Comma-separated list of allowed origins for cross-origin requests
# In development, defaults to localhost:3000, localhost:5173, etc.
# In production, this MUST be set explicitly
# Example: ALLOWED_ORIGINS=https://app.example.com,https://admin.example.com
ALLOWED_ORIGINS=

# Logging
LOG_LEVEL=info

# =============================================================================
# Monitoring & Evaluation
# =============================================================================

# LangSmith Configuration (for LLM tracing)
# Get API key from https://smith.langchain.com
LANGSMITH_API_KEY=
LANGSMITH_PROJECT=rag-notion
LANGSMITH_ENABLED=true

# RAGAS Microservice Configuration (for quality evaluation)
RAGAS_SERVICE_URL=http://localhost:8001
RAGAS_TIMEOUT=60000

# =============================================================================
# Chunking & Embedding Tuning (Phase 1 + Phase 5)
# =============================================================================

# Enable per-request retrieval trace logging (debug level)
LOG_RETRIEVAL_TRACE=false

# Maximum tokens per semantic group
# Phase 5: Reduced to 400 (was 500) for tighter chunk variance
MAX_GROUP_TOKENS=400

# Minimum tokens for a chunk to remain standalone; smaller chunks merge
# Phase 5: Increased to 200 (was 50) for consistent 200-400 token range
MIN_GROUP_TOKENS=200

# Minimum tokens for a standalone chunk (legacy, kept for compatibility)
MIN_STANDALONE_TOKENS=50

# Maximum list items per chunk before splitting
# Phase 5: Prevents over-grouping of long lists
MAX_LIST_ITEMS=15

# Embedding model context window in tokens (used to compute maxCharsPerChunk)
# text-embedding-3-small: 8192 (default)
EMBEDDING_CONTEXT_TOKENS=8192

# Set to true after deploying chunking changes; warns on startup that
# existing Qdrant vectors use the old chunking strategy and need re-indexing.
# Set to false after a full re-sync is complete.
PENDING_REINDEX=false

# =============================================================================
# Chunk Quality Filters (Phase 4 + Phase 5)
# =============================================================================

# Enables filtering of low-quality chunks (tiny, junk patterns) after reranking
# but before LLM context construction. Set to 'false' to disable (kill-switch).
ENABLE_CHUNK_FILTER=true

# Enable code chunk filtering based on query intent
# When true, code chunks are only included for programming-related queries
# Phase 5: Addresses code-heavy documents dominating non-code queries
ENABLE_CODE_FILTER=true

# Use tiktoken for accurate token counting (requires js-tiktoken)
# When false, uses fast language-aware heuristic (~15% error margin)
USE_TIKTOKEN=false

# =============================================================================
# Multi-Tenant Security (Defense-in-Depth)
# =============================================================================
# Enforces workspaceId filtering at the vector store layer
# When enabled, ALL Qdrant searches MUST include metadata.workspaceId filter
# This is a defense-in-depth measure that prevents workspace data leakage
# even if higher-level filter construction is bypassed
# WARNING: Only set to 'false' in isolated single-tenant environments
ENFORCE_TENANT_ISOLATION=true

# =============================================================================
# Notion Sync Job Recovery (ISSUE #16 FIX)
# =============================================================================
# Automatic detection and recovery of stalled sync jobs

# Hours before a sync job is considered stale (default: 2 hours)
# Full syncs of large workspaces may need longer timeouts
STALE_JOB_TIMEOUT_HOURS=2

# Maximum automatic recovery attempts before permanent failure
MAX_SYNC_RECOVERY_ATTEMPTS=2

# Minutes without progress before a job is flagged as stalled
SYNC_PROGRESS_TIMEOUT_MINUTES=30

# =============================================================================
# Notion Token Health Monitoring
# =============================================================================
# Enable/disable the token health monitor service
NOTION_TOKEN_MONITOR_ENABLED=true

# How often to check token health (in hours)
TOKEN_CHECK_INTERVAL_HOURS=6

# Enable automatic reconnection attempts (future feature)
NOTION_AUTO_RECONNECT=false

# Enable email notifications when tokens expire
NOTION_TOKEN_EMAIL_NOTIFICATIONS=true


# =============================================================================
# Email Configuration (Resend HTTP API)
# =============================================================================
# Resend API key (get from https://resend.com/api-keys)
RESEND_API_KEY=
SMTP_FROM_NAME=Retrieva
RESEND_FROM_EMAIL=noreply@devandre.sbs

# Hallucination blocking
GUARDRAIL_STRICT_HALLUCINATION_BLOCKING=true  # Block on hasHallucinations alone
GUARDRAIL_HALLUCINATION_REQUIRE_BOTH=false    # Legacy compound condition

# Seed for reproducibility
GUARDRAIL_LLM_SEED=                           # Set for deterministic outputs (e.g., 12345)
GUARDRAIL_USE_SEED_CRITICAL=false             # Enable for evaluation flows

# =============================================================================
# Context Expansion (Parent/Sibling Document Retrieval)
# =============================================================================
# Fetch surrounding chunks for better context

# Enable/disable context expansion
ENABLE_CONTEXT_EXPANSION=true

# Number of sibling chunks to fetch before and after each retrieved chunk
SIBLING_WINDOW_SIZE=1

# Maximum chunks to fetch from a single source document
MAX_CHUNKS_PER_SOURCE=5

# Minimum semantic score for a chunk to be expanded
MIN_SCORE_FOR_EXPANSION=0.5

# =============================================================================
# Cross-Encoder Re-ranking
# =============================================================================
# Neural re-ranking for improved document ranking quality
# Recommended: Enable for better retrieval quality (uses LLM to re-rank docs)

# Enable cross-encoder re-ranking (recommended: true)
ENABLE_CROSS_ENCODER_RERANK=true

# Re-ranking provider: 'cohere', 'llm', or 'none'
RERANK_PROVIDER=llm

# Cohere API key (required if RERANK_PROVIDER=cohere)
COHERE_API_KEY=

# Cohere model for re-ranking
COHERE_RERANK_MODEL=rerank-english-v3.0

# Number of top documents to return after re-ranking
RERANK_TOP_N=5

# Minimum re-rank score threshold
RERANK_MIN_SCORE=0.1

# Re-ranking request timeout in milliseconds
RERANK_TIMEOUT=10000

# Cache TTL for re-ranking results (seconds)
RERANK_CACHE_TTL=300

# =============================================================================
# Advanced Retrieval Filters
# =============================================================================
# Additional metadata filters for retrieval queries

# Date range filter (supports ISO dates in query)
# Example filter: { dateRange: { from: '2024-01-01', to: '2024-12-31' } }

# Author filter (matches metadata.author field)
# Example filter: { author: 'John Doe' }

# Document type filter
# Allowed values: page, database, file, folder
# Example filter: { documentType: 'page' }

# Document classification filter (for access control)
# Allowed values: public, internal, confidential, restricted
# Example exact match: { classification: 'internal' }
# Example level-based (includes all at/below level):
#   { classificationLevel: 'confidential' } -> returns public, internal, confidential

# Tags filter (any match)
# Example filter: { tags: ['important', 'reviewed'] }

# =============================================================================
# Document Classification Defaults
# =============================================================================
# Default classification for new documents (used if not specified in source)
DEFAULT_DOCUMENT_CLASSIFICATION=internal

# Notion property name to read classification from (if exists)
# Set to the name of a "Select" property in your Notion database
# Example: If your Notion DB has a "Sensitivity" select property with
# options: Public, Internal, Confidential, Restricted
NOTION_CLASSIFICATION_PROPERTY=
